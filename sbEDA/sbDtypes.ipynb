{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_cancer</th>\n",
       "      <th>mean_radius</th>\n",
       "      <th>mean_texture</th>\n",
       "      <th>mean_perimeter</th>\n",
       "      <th>mean_area</th>\n",
       "      <th>mean_smoothness</th>\n",
       "      <th>mean_compactness</th>\n",
       "      <th>mean_concavity</th>\n",
       "      <th>mean_concave_points</th>\n",
       "      <th>mean_symmetry</th>\n",
       "      <th>...</th>\n",
       "      <th>worst_texture</th>\n",
       "      <th>worst_perimeter</th>\n",
       "      <th>worst_area</th>\n",
       "      <th>worst_smoothness</th>\n",
       "      <th>worst_compactness</th>\n",
       "      <th>worst_concavity</th>\n",
       "      <th>worst_concave_points</th>\n",
       "      <th>worst_symmetry</th>\n",
       "      <th>worst_fractal_dimension</th>\n",
       "      <th>mean_rad_gt_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   has_cancer  mean_radius  mean_texture  mean_perimeter  mean_area  \\\n",
       "0           1        17.99         10.38          122.80     1001.0   \n",
       "1           1        20.57         17.77          132.90     1326.0   \n",
       "2           1        19.69         21.25          130.00     1203.0   \n",
       "3           1        11.42         20.38           77.58      386.1   \n",
       "4           1        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   mean_smoothness  mean_compactness  mean_concavity  mean_concave_points  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   mean_symmetry  ...  worst_texture  worst_perimeter  worst_area  \\\n",
       "0         0.2419  ...          17.33           184.60      2019.0   \n",
       "1         0.1812  ...          23.41           158.80      1956.0   \n",
       "2         0.2069  ...          25.53           152.50      1709.0   \n",
       "3         0.2597  ...          26.50            98.87       567.7   \n",
       "4         0.1809  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst_smoothness  worst_compactness  worst_concavity  worst_concave_points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst_symmetry  worst_fractal_dimension  mean_rad_gt_mean  \n",
       "0          0.4601                  0.11890              True  \n",
       "1          0.2750                  0.08902              True  \n",
       "2          0.3613                  0.08758              True  \n",
       "3          0.6638                  0.17300             False  \n",
       "4          0.2364                  0.07678              True  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "cancer = pd.read_parquet('./Binary/data/cancer.parquet')\n",
    "cancer['mean_rad_gt_mean'] = cancer['mean_radius'] > cancer['mean_radius'].mean()\n",
    "cancer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbDtypes import ColDType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "564    1\n",
       "565    1\n",
       "566    1\n",
       "567    1\n",
       "568    0\n",
       "Name: has_cancer, Length: 569, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.has_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ints</th>\n",
       "      <th>chars1</th>\n",
       "      <th>chars3</th>\n",
       "      <th>bools</th>\n",
       "      <th>missing_ints</th>\n",
       "      <th>missing_chars1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>true</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>true</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>true</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>true</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>true</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ints chars1 chars3  bools  missing_ints missing_chars1\n",
       "0     1    yes   true   True           1.0           None\n",
       "1     1    yes   true   True           1.0           None\n",
       "2     1    yes   true   True           1.0           None\n",
       "3     1    yes   true   True           1.0           None\n",
       "4     1    yes   true   True           1.0           None"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('./binary_tests.parquet')\n",
    "df['missing_ints'] = df['ints'].apply(lambda x: None if ((x % 2 == 0) and (np.random.random() <= 0.5)) else x)\n",
    "df['missing_chars1'] = df['chars1'].apply(lambda x: None if x == 'yes' else x)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('./binary_tests.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "missing_ints\n",
       "1.0    212\n",
       "0.0    185\n",
       "NaN    172\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.missing_ints.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "564    1\n",
       "565    1\n",
       "566    1\n",
       "567    1\n",
       "568    0\n",
       "Name: ints, Length: 569, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = ColDType(df.ints)\n",
    "c.GetS(drop_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2020-01-01\n",
       "1    2020-01-02\n",
       "2    2020-01-03\n",
       "3    2020-01-04\n",
       "4    2020-01-05\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = pd.Series(pd.Timestamp('2020-01-01') for i in range(15000)).astype('datetime64[ns]') + pd.Series(pd.Timedelta(days=i) for i in range(15000))\n",
    "dates = dates.astype(str)\n",
    "dates[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mSignature:\u001b[0m\n",
      "\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0marg\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'DatetimeScalarOrArrayConvertible | DictConvertible'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0merrors\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'DateTimeErrorChoices'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'raise'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdayfirst\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0myearfirst\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mutc\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mformat\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'str | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mexact\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool | lib.NoDefault'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m<\u001b[0m\u001b[0mno_default\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0munit\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'str | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0minfer_datetime_format\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'lib.NoDefault | bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m<\u001b[0m\u001b[0mno_default\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0morigin\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'str'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'unix'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcache\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m'DatetimeIndex | Series | DatetimeScalar | NaTType | None'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m\n",
      "Convert argument to datetime.\n",
      "\n",
      "This function converts a scalar, array-like, :class:`Series` or\n",
      ":class:`DataFrame`/dict-like to a pandas datetime object.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "arg : int, float, str, datetime, list, tuple, 1-d array, Series, DataFrame/dict-like\n",
      "    The object to convert to a datetime. If a :class:`DataFrame` is provided, the\n",
      "    method expects minimally the following columns: :const:`\"year\"`,\n",
      "    :const:`\"month\"`, :const:`\"day\"`.\n",
      "errors : {'ignore', 'raise', 'coerce'}, default 'raise'\n",
      "    - If :const:`'raise'`, then invalid parsing will raise an exception.\n",
      "    - If :const:`'coerce'`, then invalid parsing will be set as :const:`NaT`.\n",
      "    - If :const:`'ignore'`, then invalid parsing will return the input.\n",
      "dayfirst : bool, default False\n",
      "    Specify a date parse order if `arg` is str or is list-like.\n",
      "    If :const:`True`, parses dates with the day first, e.g. :const:`\"10/11/12\"`\n",
      "    is parsed as :const:`2012-11-10`.\n",
      "\n",
      "    .. warning::\n",
      "\n",
      "        ``dayfirst=True`` is not strict, but will prefer to parse\n",
      "        with day first.\n",
      "\n",
      "yearfirst : bool, default False\n",
      "    Specify a date parse order if `arg` is str or is list-like.\n",
      "\n",
      "    - If :const:`True` parses dates with the year first, e.g.\n",
      "      :const:`\"10/11/12\"` is parsed as :const:`2010-11-12`.\n",
      "    - If both `dayfirst` and `yearfirst` are :const:`True`, `yearfirst` is\n",
      "      preceded (same as :mod:`dateutil`).\n",
      "\n",
      "    .. warning::\n",
      "\n",
      "        ``yearfirst=True`` is not strict, but will prefer to parse\n",
      "        with year first.\n",
      "\n",
      "utc : bool, default False\n",
      "    Control timezone-related parsing, localization and conversion.\n",
      "\n",
      "    - If :const:`True`, the function *always* returns a timezone-aware\n",
      "      UTC-localized :class:`Timestamp`, :class:`Series` or\n",
      "      :class:`DatetimeIndex`. To do this, timezone-naive inputs are\n",
      "      *localized* as UTC, while timezone-aware inputs are *converted* to UTC.\n",
      "\n",
      "    - If :const:`False` (default), inputs will not be coerced to UTC.\n",
      "      Timezone-naive inputs will remain naive, while timezone-aware ones\n",
      "      will keep their time offsets. Limitations exist for mixed\n",
      "      offsets (typically, daylight savings), see :ref:`Examples\n",
      "      <to_datetime_tz_examples>` section for details.\n",
      "\n",
      "    See also: pandas general documentation about `timezone conversion and\n",
      "    localization\n",
      "    <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html\n",
      "    #time-zone-handling>`_.\n",
      "\n",
      "format : str, default None\n",
      "    The strftime to parse time, e.g. :const:`\"%d/%m/%Y\"`. See\n",
      "    `strftime documentation\n",
      "    <https://docs.python.org/3/library/datetime.html\n",
      "    #strftime-and-strptime-behavior>`_ for more information on choices, though\n",
      "    note that :const:`\"%f\"` will parse all the way up to nanoseconds.\n",
      "    You can also pass:\n",
      "\n",
      "    - \"ISO8601\", to parse any `ISO8601 <https://en.wikipedia.org/wiki/ISO_8601>`_\n",
      "      time string (not necessarily in exactly the same format);\n",
      "    - \"mixed\", to infer the format for each element individually. This is risky,\n",
      "      and you should probably use it along with `dayfirst`.\n",
      "exact : bool, default True\n",
      "    Control how `format` is used:\n",
      "\n",
      "    - If :const:`True`, require an exact `format` match.\n",
      "    - If :const:`False`, allow the `format` to match anywhere in the target\n",
      "      string.\n",
      "\n",
      "    Cannot be used alongside ``format='ISO8601'`` or ``format='mixed'``.\n",
      "unit : str, default 'ns'\n",
      "    The unit of the arg (D,s,ms,us,ns) denote the unit, which is an\n",
      "    integer or float number. This will be based off the origin.\n",
      "    Example, with ``unit='ms'`` and ``origin='unix'``, this would calculate\n",
      "    the number of milliseconds to the unix epoch start.\n",
      "infer_datetime_format : bool, default False\n",
      "    If :const:`True` and no `format` is given, attempt to infer the format\n",
      "    of the datetime strings based on the first non-NaN element,\n",
      "    and if it can be inferred, switch to a faster method of parsing them.\n",
      "    In some cases this can increase the parsing speed by ~5-10x.\n",
      "\n",
      "    .. deprecated:: 2.0.0\n",
      "        A strict version of this argument is now the default, passing it has\n",
      "        no effect.\n",
      "\n",
      "origin : scalar, default 'unix'\n",
      "    Define the reference date. The numeric values would be parsed as number\n",
      "    of units (defined by `unit`) since this reference date.\n",
      "\n",
      "    - If :const:`'unix'` (or POSIX) time; origin is set to 1970-01-01.\n",
      "    - If :const:`'julian'`, unit must be :const:`'D'`, and origin is set to\n",
      "      beginning of Julian Calendar. Julian day number :const:`0` is assigned\n",
      "      to the day starting at noon on January 1, 4713 BC.\n",
      "    - If Timestamp convertible (Timestamp, dt.datetime, np.datetimt64 or date\n",
      "      string), origin is set to Timestamp identified by origin.\n",
      "    - If a float or integer, origin is the millisecond difference\n",
      "      relative to 1970-01-01.\n",
      "cache : bool, default True\n",
      "    If :const:`True`, use a cache of unique, converted dates to apply the\n",
      "    datetime conversion. May produce significant speed-up when parsing\n",
      "    duplicate date strings, especially ones with timezone offsets. The cache\n",
      "    is only used when there are at least 50 values. The presence of\n",
      "    out-of-bounds values will render the cache unusable and may slow down\n",
      "    parsing.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "datetime\n",
      "    If parsing succeeded.\n",
      "    Return type depends on input (types in parenthesis correspond to\n",
      "    fallback in case of unsuccessful timezone or out-of-range timestamp\n",
      "    parsing):\n",
      "\n",
      "    - scalar: :class:`Timestamp` (or :class:`datetime.datetime`)\n",
      "    - array-like: :class:`DatetimeIndex` (or :class:`Series` with\n",
      "      :class:`object` dtype containing :class:`datetime.datetime`)\n",
      "    - Series: :class:`Series` of :class:`datetime64` dtype (or\n",
      "      :class:`Series` of :class:`object` dtype containing\n",
      "      :class:`datetime.datetime`)\n",
      "    - DataFrame: :class:`Series` of :class:`datetime64` dtype (or\n",
      "      :class:`Series` of :class:`object` dtype containing\n",
      "      :class:`datetime.datetime`)\n",
      "\n",
      "Raises\n",
      "------\n",
      "ParserError\n",
      "    When parsing a date from string fails.\n",
      "ValueError\n",
      "    When another datetime conversion error happens. For example when one\n",
      "    of 'year', 'month', day' columns is missing in a :class:`DataFrame`, or\n",
      "    when a Timezone-aware :class:`datetime.datetime` is found in an array-like\n",
      "    of mixed time offsets, and ``utc=False``.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "DataFrame.astype : Cast argument to a specified dtype.\n",
      "to_timedelta : Convert argument to timedelta.\n",
      "convert_dtypes : Convert dtypes.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "\n",
      "Many input types are supported, and lead to different output types:\n",
      "\n",
      "- **scalars** can be int, float, str, datetime object (from stdlib :mod:`datetime`\n",
      "  module or :mod:`numpy`). They are converted to :class:`Timestamp` when\n",
      "  possible, otherwise they are converted to :class:`datetime.datetime`.\n",
      "  None/NaN/null scalars are converted to :const:`NaT`.\n",
      "\n",
      "- **array-like** can contain int, float, str, datetime objects. They are\n",
      "  converted to :class:`DatetimeIndex` when possible, otherwise they are\n",
      "  converted to :class:`Index` with :class:`object` dtype, containing\n",
      "  :class:`datetime.datetime`. None/NaN/null entries are converted to\n",
      "  :const:`NaT` in both cases.\n",
      "\n",
      "- **Series** are converted to :class:`Series` with :class:`datetime64`\n",
      "  dtype when possible, otherwise they are converted to :class:`Series` with\n",
      "  :class:`object` dtype, containing :class:`datetime.datetime`. None/NaN/null\n",
      "  entries are converted to :const:`NaT` in both cases.\n",
      "\n",
      "- **DataFrame/dict-like** are converted to :class:`Series` with\n",
      "  :class:`datetime64` dtype. For each row a datetime is created from assembling\n",
      "  the various dataframe columns. Column keys can be common abbreviations\n",
      "  like [â€˜yearâ€™, â€˜monthâ€™, â€˜dayâ€™, â€˜minuteâ€™, â€˜secondâ€™, â€˜msâ€™, â€˜usâ€™, â€˜nsâ€™]) or\n",
      "  plurals of the same.\n",
      "\n",
      "The following causes are responsible for :class:`datetime.datetime` objects\n",
      "being returned (possibly inside an :class:`Index` or a :class:`Series` with\n",
      ":class:`object` dtype) instead of a proper pandas designated type\n",
      "(:class:`Timestamp`, :class:`DatetimeIndex` or :class:`Series`\n",
      "with :class:`datetime64` dtype):\n",
      "\n",
      "- when any input element is before :const:`Timestamp.min` or after\n",
      "  :const:`Timestamp.max`, see `timestamp limitations\n",
      "  <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html\n",
      "  #timeseries-timestamp-limits>`_.\n",
      "\n",
      "- when ``utc=False`` (default) and the input is an array-like or\n",
      "  :class:`Series` containing mixed naive/aware datetime, or aware with mixed\n",
      "  time offsets. Note that this happens in the (quite frequent) situation when\n",
      "  the timezone has a daylight savings policy. In that case you may wish to\n",
      "  use ``utc=True``.\n",
      "\n",
      "Examples\n",
      "--------\n",
      "\n",
      "**Handling various input formats**\n",
      "\n",
      "Assembling a datetime from multiple columns of a :class:`DataFrame`. The keys\n",
      "can be common abbreviations like ['year', 'month', 'day', 'minute', 'second',\n",
      "'ms', 'us', 'ns']) or plurals of the same\n",
      "\n",
      ">>> df = pd.DataFrame({'year': [2015, 2016],\n",
      "...                    'month': [2, 3],\n",
      "...                    'day': [4, 5]})\n",
      ">>> pd.to_datetime(df)\n",
      "0   2015-02-04\n",
      "1   2016-03-05\n",
      "dtype: datetime64[ns]\n",
      "\n",
      "Using a unix epoch time\n",
      "\n",
      ">>> pd.to_datetime(1490195805, unit='s')\n",
      "Timestamp('2017-03-22 15:16:45')\n",
      ">>> pd.to_datetime(1490195805433502912, unit='ns')\n",
      "Timestamp('2017-03-22 15:16:45.433502912')\n",
      "\n",
      ".. warning:: For float arg, precision rounding might happen. To prevent\n",
      "    unexpected behavior use a fixed-width exact type.\n",
      "\n",
      "Using a non-unix epoch origin\n",
      "\n",
      ">>> pd.to_datetime([1, 2, 3], unit='D',\n",
      "...                origin=pd.Timestamp('1960-01-01'))\n",
      "DatetimeIndex(['1960-01-02', '1960-01-03', '1960-01-04'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "\n",
      "**Differences with strptime behavior**\n",
      "\n",
      ":const:`\"%f\"` will parse all the way up to nanoseconds.\n",
      "\n",
      ">>> pd.to_datetime('2018-10-26 12:00:00.0000000011',\n",
      "...                format='%Y-%m-%d %H:%M:%S.%f')\n",
      "Timestamp('2018-10-26 12:00:00.000000001')\n",
      "\n",
      "**Non-convertible date/times**\n",
      "\n",
      "If a date does not meet the `timestamp limitations\n",
      "<https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html\n",
      "#timeseries-timestamp-limits>`_, passing ``errors='ignore'``\n",
      "will return the original input instead of raising any exception.\n",
      "\n",
      "Passing ``errors='coerce'`` will force an out-of-bounds date to :const:`NaT`,\n",
      "in addition to forcing non-dates (or non-parseable dates) to :const:`NaT`.\n",
      "\n",
      ">>> pd.to_datetime('13000101', format='%Y%m%d', errors='ignore')\n",
      "'13000101'\n",
      ">>> pd.to_datetime('13000101', format='%Y%m%d', errors='coerce')\n",
      "NaT\n",
      "\n",
      ".. _to_datetime_tz_examples:\n",
      "\n",
      "**Timezones and time offsets**\n",
      "\n",
      "The default behaviour (``utc=False``) is as follows:\n",
      "\n",
      "- Timezone-naive inputs are converted to timezone-naive :class:`DatetimeIndex`:\n",
      "\n",
      ">>> pd.to_datetime(['2018-10-26 12:00:00', '2018-10-26 13:00:15'])\n",
      "DatetimeIndex(['2018-10-26 12:00:00', '2018-10-26 13:00:15'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "\n",
      "- Timezone-aware inputs *with constant time offset* are converted to\n",
      "  timezone-aware :class:`DatetimeIndex`:\n",
      "\n",
      ">>> pd.to_datetime(['2018-10-26 12:00 -0500', '2018-10-26 13:00 -0500'])\n",
      "DatetimeIndex(['2018-10-26 12:00:00-05:00', '2018-10-26 13:00:00-05:00'],\n",
      "              dtype='datetime64[ns, UTC-05:00]', freq=None)\n",
      "\n",
      "- However, timezone-aware inputs *with mixed time offsets* (for example\n",
      "  issued from a timezone with daylight savings, such as Europe/Paris)\n",
      "  are **not successfully converted** to a :class:`DatetimeIndex`. Instead a\n",
      "  simple :class:`Index` containing :class:`datetime.datetime` objects is\n",
      "  returned:\n",
      "\n",
      ">>> pd.to_datetime(['2020-10-25 02:00 +0200', '2020-10-25 04:00 +0100'])\n",
      "Index([2020-10-25 02:00:00+02:00, 2020-10-25 04:00:00+01:00],\n",
      "      dtype='object')\n",
      "\n",
      "- A mix of timezone-aware and timezone-naive inputs is also converted to\n",
      "  a simple :class:`Index` containing :class:`datetime.datetime` objects:\n",
      "\n",
      ">>> from datetime import datetime\n",
      ">>> pd.to_datetime([\"2020-01-01 01:00:00-01:00\", datetime(2020, 1, 1, 3, 0)])\n",
      "Index([2020-01-01 01:00:00-01:00, 2020-01-01 03:00:00], dtype='object')\n",
      "\n",
      "|\n",
      "\n",
      "Setting ``utc=True`` solves most of the above issues:\n",
      "\n",
      "- Timezone-naive inputs are *localized* as UTC\n",
      "\n",
      ">>> pd.to_datetime(['2018-10-26 12:00', '2018-10-26 13:00'], utc=True)\n",
      "DatetimeIndex(['2018-10-26 12:00:00+00:00', '2018-10-26 13:00:00+00:00'],\n",
      "              dtype='datetime64[ns, UTC]', freq=None)\n",
      "\n",
      "- Timezone-aware inputs are *converted* to UTC (the output represents the\n",
      "  exact same datetime, but viewed from the UTC time offset `+00:00`).\n",
      "\n",
      ">>> pd.to_datetime(['2018-10-26 12:00 -0530', '2018-10-26 12:00 -0500'],\n",
      "...                utc=True)\n",
      "DatetimeIndex(['2018-10-26 17:30:00+00:00', '2018-10-26 17:00:00+00:00'],\n",
      "              dtype='datetime64[ns, UTC]', freq=None)\n",
      "\n",
      "- Inputs can contain both string or datetime, the above\n",
      "  rules still apply\n",
      "\n",
      ">>> pd.to_datetime(['2018-10-26 12:00', datetime(2020, 1, 1, 18)], utc=True)\n",
      "DatetimeIndex(['2018-10-26 12:00:00+00:00', '2020-01-01 18:00:00+00:00'],\n",
      "              dtype='datetime64[ns, UTC]', freq=None)\n",
      "\u001b[1;31mFile:\u001b[0m      c:\\users\\aweaver\\sb-eda\\.env\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\n",
      "\u001b[1;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "pd.to_datetime?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1: s.dtype: datetime64[ns]\n",
      "\n",
      "s: 0       2020-01-01\n",
      "1       2020-01-02\n",
      "2       2020-01-03\n",
      "3       2020-01-04\n",
      "4       2020-01-05\n",
      "           ...    \n",
      "14995   2061-01-20\n",
      "14996   2061-01-21\n",
      "14997   2061-01-22\n",
      "14998   2061-01-23\n",
      "14999   2061-01-24\n",
      "Length: 15000, dtype: datetime64[ns]\n",
      "\n",
      "2\n",
      "2: s_fmt.dtype: datetime64[ns]\n",
      "\n",
      "s_fmt: 0       2020-01-01\n",
      "1       2020-01-02\n",
      "2       2020-01-03\n",
      "3       2020-01-04\n",
      "4       2020-01-05\n",
      "           ...    \n",
      "14995   2061-01-20\n",
      "14996   2061-01-21\n",
      "14997   2061-01-22\n",
      "14998   2061-01-23\n",
      "14999   2061-01-24\n",
      "Length: 15000, dtype: datetime64[ns]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       2020-01-01\n",
       "1       2020-01-02\n",
       "2       2020-01-03\n",
       "3       2020-01-04\n",
       "4       2020-01-05\n",
       "           ...    \n",
       "14995   2061-01-20\n",
       "14996   2061-01-21\n",
       "14997   2061-01-22\n",
       "14998   2061-01-23\n",
       "14999   2061-01-24\n",
       "Length: 15000, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = ColDType(dates)\n",
    "d.sb_dtype(return_=True)\n",
    "d.format_series()\n",
    "d.s_fmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              None\n",
       "1        2020-01-02\n",
       "2        2020-01-03\n",
       "3        2020-01-04\n",
       "4        2020-01-05\n",
       "            ...    \n",
       "14995    2061-01-20\n",
       "14996    2061-01-21\n",
       "14997    2061-01-22\n",
       "14998    2061-01-23\n",
       "14999    2061-01-24\n",
       "Length: 15000, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates_w_missing = dates.copy()\n",
    "\n",
    "# randomly drop 30% of the dates\n",
    "dates_w_missing = dates_w_missing.apply(lambda x: None if np.random.random() <= 0.3 else x)\n",
    "dates_w_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date\n",
      "1\n",
      "1: s.dtype: datetime64[ns]\n",
      "\n",
      "s: 0       1970-01-01\n",
      "1       2020-01-02\n",
      "2       2020-01-03\n",
      "3       2020-01-04\n",
      "4       2020-01-05\n",
      "           ...    \n",
      "14995   2061-01-20\n",
      "14996   2061-01-21\n",
      "14997   2061-01-22\n",
      "14998   2061-01-23\n",
      "14999   2061-01-24\n",
      "Length: 15000, dtype: datetime64[ns]\n",
      "\n",
      "2\n",
      "2: s_fmt.dtype: datetime64[ns]\n",
      "\n",
      "s_fmt: 0       1970-01-01\n",
      "1       2020-01-02\n",
      "2       2020-01-03\n",
      "3       2020-01-04\n",
      "4       2020-01-05\n",
      "           ...    \n",
      "14995   2061-01-20\n",
      "14996   2061-01-21\n",
      "14997   2061-01-22\n",
      "14998   2061-01-23\n",
      "14999   2061-01-24\n",
      "Length: 15000, dtype: datetime64[ns]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       1970-01-01\n",
       "1       2020-01-02\n",
       "2       2020-01-03\n",
       "3       2020-01-04\n",
       "4       2020-01-05\n",
       "           ...    \n",
       "14995   2061-01-20\n",
       "14996   2061-01-21\n",
       "14997   2061-01-22\n",
       "14998   2061-01-23\n",
       "14999   2061-01-24\n",
       "Length: 15000, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = ColDType(dates_w_missing)\n",
    "d.sb_dtype(return_=True)\n",
    "print(d.sb_dtype(return_=True))\n",
    "d.format_series()\n",
    "d.s_fmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ints: binary\n",
      "\n",
      "value_counts:\n",
      "ints\n",
      "0    357\n",
      "1    212\n",
      "Name: count, dtype: int64\n",
      "chars1: binary\n",
      "\n",
      "value_counts:\n",
      "chars1\n",
      "0    357\n",
      "1    212\n",
      "Name: count, dtype: int64\n",
      "chars3: binary\n",
      "\n",
      "value_counts:\n",
      "chars3\n",
      "0    357\n",
      "1    212\n",
      "Name: count, dtype: int64\n",
      "bools: binary\n",
      "\n",
      "value_counts:\n",
      "bools\n",
      "0    357\n",
      "1    212\n",
      "Name: count, dtype: int64\n",
      "missing_ints: binary\n",
      "\n",
      "value_counts:\n",
      "missing_ints\n",
      " 1       212\n",
      " 0       185\n",
      "-9999    172\n",
      "Name: count, dtype: int64\n",
      "missing_chars1: binary\n",
      "\n",
      "value_counts:\n",
      "missing_chars1\n",
      " 0       357\n",
      "-9999    212\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for c in df.columns.tolist():\n",
    "    # if c not in ['chars2', 'chars4']:\n",
    "    tempcol = ColDType(df[c])\n",
    "    print(f\"{c}: {tempcol.sb_dtype(return_=True)}\")\n",
    "    tempcol.format_series()\n",
    "    print(f\"\\nvalue_counts:\\n{tempcol.s_fmt.value_counts()}\")\n",
    "    assert tempcol.sb_dtype(return_=True) == 'binary', \\\n",
    "        f\"Column {c} should be binary but is {tempcol.sb_dtype(return_=True)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColDType(missing_ints)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = ColDType(df.missing_ints)\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "missing_ints\n",
       "1.0    212\n",
       "0.0    185\n",
       "NaN    172\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col.s.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    0.0\n",
       "2    NaN\n",
       "Name: missing_ints, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col.s.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    0.0\n",
       "2    NaN\n",
       "Name: missing_ints, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col.get_unique_values() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'missing_ints'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col.s.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col.is_type_known"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "col.is_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    0.0\n",
       "2    NaN\n",
       "Name: missing_ints, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col.get_unique_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'binary'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col.sb_dtype(return_=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col.is_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "col.s_fmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1.0\n",
       "1      1.0\n",
       "2      1.0\n",
       "3      1.0\n",
       "4      1.0\n",
       "      ... \n",
       "564    1.0\n",
       "565    1.0\n",
       "566    1.0\n",
       "567    1.0\n",
       "568    NaN\n",
       "Name: missing_ints, Length: 569, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_map = {\n",
    "            0: 0,\n",
    "            1: 1,\n",
    "            True: 1,\n",
    "            False: 0,\n",
    "            \"yes\": 1,\n",
    "            \"no\": 0,\n",
    "            \"y\": 1,\n",
    "            \"n\": 0,\n",
    "            \"t\": 1,\n",
    "            \"f\": 0,\n",
    "            \"true\": 1,\n",
    "            \"false\": 0,\n",
    "        }\n",
    "\n",
    "col.GetS(replace_na=col.binary_na_fill).map(binary_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "col.format_binary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "missing_ints\n",
       "1.0    212\n",
       "0.0    185\n",
       "NaN    172\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col.s.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "missing_ints\n",
       " 1       212\n",
       " 0       185\n",
       "-9999    172\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col.s_fmt.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c795e80111f2cb22080f8479d9d687ea36728ec54dabbc03035f499aaa40747"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
